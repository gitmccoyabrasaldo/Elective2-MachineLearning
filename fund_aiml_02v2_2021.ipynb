{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6Xl67Tc7ZHNG"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmccoyabrasaldo/Elective2-MachineLearning/blob/main/fund_aiml_02v2_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pZmxroJS0I"
      },
      "source": [
        "# Topic 02: Review of Linear Algebra\n",
        "$_{\\text{Â©D.J. Lopez | 2021 | Fudamentals of Machine Learning}}$\n",
        "\n",
        "Linear algebra is undoubtfully one of the foundations of Machine Learning. Through linear algebra, we can perform more optimized techniques in computing an array of numbers wherein mostly used in Machine Learning. In this chapter, we are going to review the concepts, theories, and operations in Linear Algebra that are useful in Machine Learning. For this notebook we will be covering the following topics:\n",
        "* Vector and Matrix Representation\n",
        "* Linear Transformation and Matrix Operations\n",
        "* Vectorization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ8ykwKm05jH"
      },
      "source": [
        "# Vector and Matrix Representation\n",
        "\n",
        "Vectors and Matrices are the fundamental objects in Linear Algebra programming. We'll be defining each of these objects specifically in the Computer Science/Engineering perspective since it would be much confusing if we consider their Physics and Pure Mathematics definitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzH9N-yR0--e"
      },
      "source": [
        "## Vectors\n",
        "Vectors are array of numerical values or scalars that would represent any feature space. Feature spaces or simply dimensions or the parameters of an equation or a function.\n",
        "\n",
        "Starting this module we will be using NumPy. NumPy or Numerical Python, is mainly used for matrix and vector operations. It is capable of declaring computing and representing matrices. Most Python scienitifc programming libraries uses NumPy as the basic code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHDwqNBv5lYe"
      },
      "source": [
        "Now that you know how to represent vectors using their component and matrix form we can now hard-code them in Python. Let's say that you have the vectors:\n",
        "\n",
        "$$ A = 4\\hat{x} + 3\\hat{y} \\\\\n",
        "B = 2\\hat{x} - 5\\hat{y}$$\n",
        "\n",
        "In which it's matrix equivalent is:\n",
        "$$ A = \\begin{bmatrix} 4 \\\\ 3\\end{bmatrix} , B = \\begin{bmatrix} 2 \\\\ -5\\end{bmatrix}\\\\\n",
        " A = \\begin{bmatrix} 4 & 3\\end{bmatrix} \\\\\n",
        " B = \\begin{bmatrix} 2 & -5\\end{bmatrix} \n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPAW8ycB5vOf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([4,3])\n",
        "B = np.array([2, -5])\n",
        "\n",
        "print('Vector A is ', A)\n",
        "print('Vector B is ', B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXluKqAO1BNe"
      },
      "source": [
        "### Linear Combinations\n",
        "\n",
        "It is said that a linear combination is the combination of linear scaling and addition of a vector its bases/components.\n",
        "We will try to visualize the vectors and their linear combinations by plotting a sample of real number values for the scalars for the vectors. Let's first try the vectors below:\n",
        "$$X = \\begin{bmatrix} 2\\\\5 \\\\\\end{bmatrix} , Y = \\begin{bmatrix} 7\\\\9 \\\\\\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8-B1WX86Dk3"
      },
      "source": [
        "vectX =  np.array([2,5])\n",
        "vectY =  np.array([7,9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcgOgrbTLpPN"
      },
      "source": [
        "Linear combinations usually have a form that takes on.\n",
        "$$a_0x_0+a_1x_1+a_2x_2+...+a_nx_n$$\n",
        "It can then be expressed as the inner product of two vectors.\n",
        "$$\\begin{bmatrix}a_0 \\\\ a_1\\\\a_2 \\\\\\vdots \\\\ a_n\\end{bmatrix} \\cdot \\begin{bmatrix}x_0 \\\\ x_1\\\\x_2 \\\\\\vdots \\\\ x_n\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSUgshVg1M-P"
      },
      "source": [
        "### Vector Spans and Spaces\n",
        "As discussed in the lecture, the span of individual vectors can be represented by a line span. Let's take vector $X$ as an example.\n",
        "$$X = c\\cdot v $$\n",
        "Where as $c$ is some scalar or range of scalars that represents the scaling factor of a vector and $v$ is any vector. In our example $v$ could be the earlier declared `vectX`.\n",
        "$$X = c\\cdot \\begin{bmatrix} 2\\\\5 \\\\\\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dNPspCF6Rn2"
      },
      "source": [
        "c = np.arange(-10,10,0.0125)\n",
        "\n",
        "plt.scatter(c*vectX[0],c*vectX[1])\n",
        "\n",
        "plt.xlim(-10,10)\n",
        "plt.ylim(-10,10)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8TnW4L66aRG"
      },
      "source": [
        "So what if we are to plot the span of a linear combination of vectors? We can visualize as a plane on the 2-dimensional coordinate system. Let's take the span of the linear combination below:\n",
        "\n",
        "$$S = \\begin{Bmatrix} c_1 \\cdot\\begin{bmatrix} 1\\\\0 \\\\\\end{bmatrix}, \n",
        "c_2 \\cdot \\begin{bmatrix} 1\\\\-1 \\\\\\end{bmatrix}\\end{Bmatrix} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQxLP60f6fVn"
      },
      "source": [
        "vectA = np.array([1,0])\n",
        "vectB = np.array([1,-1])\n",
        "\n",
        "R = np.arange(-10,10,1)\n",
        "\n",
        "c1, c2 = np.meshgrid(R,R)\n",
        "vectR = vectA + vectB\n",
        "spanRx = c1*vectA[0] + c2*vectB[0]\n",
        "spanRy = c1*vectA[1] + c2*vectB[1]\n",
        "plt.scatter(spanRx,spanRy, s=5, alpha=0.75)\n",
        "\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk1XJ2gZ6j2u"
      },
      "source": [
        "Take note that if vectors are seen to be as a 2-dimensional span we can say it has a Rank of 2 or $\\mathbb{R}^2$. But if the span of the linear combination of vectors are seen to be like a line, they are said to be <b> linearly dependent </b> and they have a rank of 1 or $\\mathbb{R}^1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DI6DA6fJouN"
      },
      "source": [
        "### Inner Product \n",
        "The inner product of a vector results into a scalar value. The purpose of this operation is to know the similarity of two different vectors through directional multiplication. The inner product of two vectors can be represented by the equation:\n",
        "$$\\sum^N_{i=0}u_i\\times v_i$$\n",
        "Whereas $u$ and $v$ are vectors wherein they both have $N$ number of elements. This can be further simplified using the inner product vector form:\n",
        "$$u\\cdot v$$\n",
        "Again still following the rule that $u$ has the same size as $v$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI_vkzBqNjX8"
      },
      "source": [
        "u = np.array([1,2,3])\n",
        "v = np.array([4,2-3])\n",
        "\n",
        "u_dot_v = u @ v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQf8P3Vt1QjO"
      },
      "source": [
        "## Matrices\n",
        "\n",
        "The notation and use of matrices is probably one of the fundamentals of modern computing. Matrices are also handy representations of complex equations or multiple inter-related equations from 2-dimensional equations to even hundreds and thousands of them.\n",
        "\n",
        "Let's say for example you have $A$ and $B$ as system of equation.\n",
        "\n",
        "$$\n",
        "A = \\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        x + y \\\\ \n",
        "        4x - 10y\n",
        "    \\end{array}\n",
        "\\right. \\\\\n",
        "B = \\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        x+y+z \\\\ \n",
        "        3x -2y -z \\\\\n",
        "        -x + 4y +2z\n",
        "    \\end{array}\n",
        "\\right. $$\n",
        "\n",
        "We could see that $A$ is a system of 2 equations with 2 parameters. While $B$ is a system of 3 equations with 3 parameters. We can represent them as matrices as:\n",
        "\n",
        "$$\n",
        "A=\\begin{bmatrix} 1 & 1 \\\\ 4 & {-10}\\end{bmatrix} \\\\\n",
        "B=\\begin{bmatrix} 1 & 1 & 1 \\\\ 3 & -2 & -1 \\\\ -1 & 4 & 2\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK8zBneJduUH"
      },
      "source": [
        "The entities or numbers in matrices are called the elements of a matrix. These elements are arranged and ordered in rows and columns which form the list/array-like structure of matrices. And just like arrays, these elements are indexed according to their position with respect to their rows and columns. This can be reprsented just like the equation below. Whereas $A$ is a matrix consisting of elements denoted by $a_{i,j}$. Denoted by $i$ is the number of rows in the matrix while $j$ stands for the number of columns.<br>\n",
        "Do note that the $size$ of a matrix is $i\\times j$.\n",
        "\n",
        "$$A=\\begin{bmatrix}\n",
        "a_{(0,0)}&a_{(0,1)}&\\dots&a_{(0,j-1)}\\\\\n",
        "a_{(1,0)}&a_{(1,1)}&\\dots&a_{(1,j-1)}\\\\\n",
        "\\vdots&\\vdots&\\ddots&\\vdots&\\\\\n",
        "a_{(i-1,0)}&a_{(i-1,1)}&\\dots&a_{(i-1,j-1)}\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T13k0Zau1TY2"
      },
      "source": [
        "### Types of Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkgGfKYTd-Ey"
      },
      "source": [
        "There are several ways of classifying matrices. Once could be according to their **shape** and another is according to their **element values**. We'll try to go through them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiTj0qx0eJUy"
      },
      "source": [
        "### According to Shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfGr9fC5eLiu"
      },
      "source": [
        "### According to Values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-pYWJOJ1qvo"
      },
      "source": [
        "# Matrix Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8yHxuv1tbm"
      },
      "source": [
        "### Arithmetic in Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcSfOsYmeUlC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdVQXwYR1wkW"
      },
      "source": [
        "### Dot Product\n",
        "If you recall the dot product from laboratory activity before, we will try to implement the same operation with matrices. In matrix dot product we are going to get the sum of products of the vectors by row-column pairs. So if we have two matrices $X$ and $Y$:\n",
        "\n",
        "$$X = \\begin{bmatrix}x_{(0,0)}&x_{(0,1)}\\\\ x_{(1,0)}&x_{(1,1)}\\end{bmatrix}, Y = \\begin{bmatrix}y_{(0,0)}&y_{(0,1)}\\\\ y_{(1,0)}&y_{(1,1)}\\end{bmatrix}$$\n",
        "\n",
        "The dot product will then be computed as:\n",
        "$$X \\cdot Y= \\begin{bmatrix} x_{(0,0)}*y_{(0,0)} + x_{(0,1)}*y_{(1,0)} & x_{(0,0)}*y_{(0,1)} + x_{(0,1)}*y_{(1,1)} \\\\  x_{(1,0)}*y_{(0,0)} + x_{(1,1)}*y_{(1,0)} & x_{(1,0)}*y_{(0,1)} + x_{(1,1)}*y_{(1,1)}\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "So if we assign values to $X$ and $Y$:\n",
        "$$X = \\begin{bmatrix}1&2\\\\ 0&1\\end{bmatrix}, Y = \\begin{bmatrix}-1&0\\\\ 2&2\\end{bmatrix}$$\n",
        "$$X \\cdot Y= \\begin{bmatrix} 1*-1 + 2*2 & 1*0 + 2*2 \\\\  0*-1 + 1*2 & 0*0 + 1*2 \\end{bmatrix} = \\begin{bmatrix} 3 & 4 \\\\2 & 2 \\end{bmatrix}$$\n",
        "This could be achieved programmatically using `np.dot()`, `np.matmul()` or the `@` operator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq-hZQcieVbS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVyob-m-1zom"
      },
      "source": [
        "### Transposition\n",
        "One of the fundamental operations in matrix algebra is Transposition. The transpose of a matrix is done by flipping the values of its elements over its diagonals. With this, the rows and columns from the original matrix will be switched. So for a matrix $A$ its transpose is denoted as $A^T$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA2mOsfKeXAK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCkgu7MleyEz"
      },
      "source": [
        "### Inversion\n",
        "The inverse of a matrix is another fundamental operation in matrix algebra. Determining the inverse of a matrix let us determine if its solvability and its characteristic as a system of linear equation â we'll expand on this in the nect module. Another use of the inverse matrix is solving the problem of divisibility between matrices. Although element-wise division exists but dividing the entire concept of matrices does not exists. Inverse matrices provides a related operation that could have the same concept of \"dividing\" matrices.\n",
        "\n",
        "Now to determine the inverse of a matrix we need to perform several steps. So let's say we have a matrix $M$:\n",
        "$$M = \\begin{bmatrix}1&7\\\\-3&5\\end{bmatrix}$$\n",
        "First, we need to get the determinant of $M$.\n",
        "$$|M| = (1)(5)-(-3)(7) = 26$$\n",
        "Next, we need to reform the matrix into the inverse form:\n",
        "$$M^{-1} = \\frac{1}{|M|} \\begin{bmatrix} m_{(1,1)} & -m_{(0,1)} \\\\ -m_{(1,0)} & m_{(0,0)}\\end{bmatrix}$$\n",
        "So that will be:\n",
        "$$M^{-1} = \\frac{1}{26} \\begin{bmatrix} 5 & -7 \\\\ 3 & 1\\end{bmatrix} = \\begin{bmatrix} \\frac{5}{26} & \\frac{-7}{26} \\\\ \\frac{3}{26} & \\frac{1}{26}\\end{bmatrix}$$\n",
        "For higher-dimension matrices you might need to use co-factors, minors, adjugates, and other reduction techinques. To solve this programmatially we can use `np.linalg.inv()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsP1eT7m3QDO"
      },
      "source": [
        "### Determinants\n",
        "Determinants are special values produced from matrix analysis. Detemrinants tell us the ratio of the values of the subspaces of the matrix. It further explains whether matrices are singular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZM5gc31eXry"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py4OmeqTgQNa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPOqh4Y5gQrj"
      },
      "source": [
        "#Eigenvalues\n",
        "<b>Eigen</b> does not denote famous actors but rather coming from a German etymology meining \"characteristic\". So we can say in analogy, that solving for the <b>eigen</b> of anything is finiding their characteristics.\n",
        "\n",
        "Referring to our definition of eigen earlier, we can deduct that eigenvectors are characteristic vectors or representative vectors of a matrix. In the more technical sense, these are vectors that can be considered constant/unchanging even when a linear transformation. So whether if we do any geometric translation, that vector in the span of the matrix will not translate to a different vector but rather just scale âmeaning it is linearly dependent from its original vector.\n",
        "\n",
        "So for example we'll have a matrix $x$ wherein we apply a matrix transformation $F$ it gives us a resulting vector $A$.\n",
        "$$F\\cdot x = A$$\n",
        "So in matrix $x$ there would exist a vector $v$ upond having a reultant matrix $A$ it will just be a scalar transform of itself (eigenvector). We can denote the scaling factor as $\\lambda$. We can then define the eigenvector as:\n",
        "$$A\\cdot v = \\lambda * v$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z3w-uVYhLIq"
      },
      "source": [
        "def plot_quiv(x,y=None,eig=None):\n",
        "    size= (5,5)\n",
        "    plt.figure(figsize=(4,4))\n",
        "          \n",
        "    plt.xlim(-size[0],size[0])\n",
        "    plt.ylim(-size[1],size[1])\n",
        "    plt.xticks(np.arange((-size[0]), size[0]+1, 1.0))\n",
        "    plt.yticks(np.arange((-size[1]), size[1]+1, 1.0))\n",
        "    \n",
        "    plt.quiver([0,0],[0,0], x[0,:], x[1,:], \n",
        "               angles='xy', scale_units='xy',scale=1, \n",
        "               color=['red','red'], label='Original Vector')## use column spaces\n",
        "    if y is not None:\n",
        "        plt.quiver([0,0],[0,0], y[0,:], y[1,:], \n",
        "               angles='xy', scale_units='xy',scale=1, \n",
        "               color=['blue','blue'], label='Transformed Vector')## use column spaces\n",
        "    if eig is not None:\n",
        "        c = np.arange(-10,10,0.25)\n",
        "#         plt.plot(c*eig[0,0],c*eig[1,0], color='orange') \n",
        "        plt.plot(c*eig[0,1], c*eig[1,1], color='orange', label='Eigenspace') \n",
        "        plt.plot(c*eig[0,0],c*eig[1,0], color='orange') \n",
        "        \n",
        "        plt.plot(c*eig[0,0], c*eig[0,1], color='orange', label='Eigenspace') \n",
        "        plt.plot(c*eig[1,0],c*eig[1,1], color='orange') \n",
        "\n",
        "        \n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx2WD1IehVVS"
      },
      "source": [
        "## Let's try to determine that manually\n",
        "x = np.array([\n",
        "    [1,-1],\n",
        "    [0,2]\n",
        "])\n",
        "plot_quiv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_PxRDxrhYrE"
      },
      "source": [
        "F = np.array([\n",
        "    [2, 1.5],\n",
        "    [0, 1]\n",
        "])\n",
        "A = F@x\n",
        "print(A)\n",
        "plot_quiv(x,A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdRHgStThckC"
      },
      "source": [
        "In the linear transformation above, we can see that the first vector (red) did not shift or rotate to any other coordinate in the 2D space. We can say that the first vector is an eigenvector since it remains on its span even if a linear transformation is applied. But do note there could be more than one eigenvector for a matrix, and most of the times these vectors cannot be identified through visual inspection. We can try to solve this using the formula we set above.\n",
        "$$(A \\cdot v) - (\\lambda * v) = 0 $$\n",
        "$$(A-\\lambda)\\cdot v = 0$$\n",
        "Assuming that $v$ is non-zero, well try to solve for $A-\\lambda$ in which it will equate to 0. Take note that $A$ is a vector and $\\lambda$ is a scalar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErTkUPzXho9B"
      },
      "source": [
        "def plot_tr_eig(inp, trans, eig, q1=False):\n",
        "    c1 = np.arange(-5, 5, 0.5)\n",
        "    c2 = np.arange(-5, 5, 0.5)\n",
        "    if q1:\n",
        "        c1 = np.arange(0, 5, 0.5)\n",
        "        c2 = np.arange(0, 5, 0.5)    \n",
        "    X,Y= np.meshgrid(c1, c2)\n",
        "    v = np.array([X.flatten(),Y.flatten()])\n",
        "    A = F@inp@v   \n",
        "\n",
        "    fig, ax = plt.subplots()    \n",
        "    size= (5,5)\n",
        "    fig.set_size_inches(10,10)\n",
        "          \n",
        "    ax.set_xlim(-size[0],size[0])\n",
        "    ax.set_ylim(-size[1],size[1])\n",
        "    ax.set_xticks(np.arange((-size[0]), size[0]+1, 1.0))\n",
        "    ax.set_yticks(np.arange((-size[1]), size[1]+1, 1.0))    \n",
        "    if q1:\n",
        "        ax.set_xlim(0,size[0])\n",
        "        ax.set_ylim(0,size[1])\n",
        "        ax.set_xticks(np.arange(0, size[0]+1, 1.0))\n",
        "        ax.set_yticks(np.arange(0, size[1]+1, 1.0))\n",
        "    q = ax.quiver(X, Y,\n",
        "                  A[0,:].reshape(int(np.sqrt(A[0,:].size)), int(np.sqrt(A[0,:].size))), \n",
        "                  A[1,:].reshape(int(np.sqrt(A[1,:].size)), int(np.sqrt(A[1,:].size))),\n",
        "                 color='royalblue')\n",
        "    ax.quiverkey(q, X=0.3, Y=1.1, U=10,\n",
        "                 label='Quiver key, length = 10', labelpos='E')    \n",
        "    if eig is not None:\n",
        "        c = np.arange(-20,20,0.25)\n",
        "        plt.plot(c*eig[0,1],c*eig[0,0], color='orange') \n",
        "        plt.plot(c*eig[1,1], c*eig[1,0], color='orange', label='Eigenvector') \n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHoekSgRhrS1"
      },
      "source": [
        "x = np.array([\n",
        "    [1,0],\n",
        "    [0,1]\n",
        "])\n",
        "F = np.array([\n",
        "    [-1,2],\n",
        "    [0,2]\n",
        "])\n",
        "eigval, eigvect = np.linalg.eig(F@x)\n",
        "plot_tr_eig(x,F,eigvect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNPt6GK3nx3"
      },
      "source": [
        "## Special Matrix Properties\n",
        "Further from the theories discussed in this notebook, we will look further in analyzing matrices with the special properties they hold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59bEkjNh39dd"
      },
      "source": [
        "### Singular Matrices/Vectors\n",
        "Singular matrices or vectors are said to converge or collapse on a dimension existing on its vector space. This can be further explain by the **Rank** of a matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajU5m6abfoai"
      },
      "source": [
        "### Rank 0 matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIDwlQMDfqi8"
      },
      "source": [
        "### Rank 1 Matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUQ-w8JAfuUa"
      },
      "source": [
        "### Rank 2 Matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBiO16E6fxhJ"
      },
      "source": [
        "### Rank N and N-1 Matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xymOswUX4BZZ"
      },
      "source": [
        "### Symmetric Vectors\n",
        "Symmetric vectors are defined as matrices that are equal to themselves even after transposition:\n",
        "$$A = A^T$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAZrBAZnincy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSjqM3ap4GvW"
      },
      "source": [
        "### Invertible Matrices\n",
        "Invertible matrices are square matrices wherein its inverse exists. A matrix is said to be invertible if it is not singular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE1vyl7_ijxK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPhDgXQ0irYy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "**END OF LABORATORY**\n",
        "\n",
        "---\n"
      ]
    }
  ]
}